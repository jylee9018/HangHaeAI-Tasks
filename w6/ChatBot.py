import base64
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

load_dotenv()

st.title("ğŸ–¼ï¸ Image Q&A Bot")
model = ChatOpenAI(model="gpt-4o-mini")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "images_encoded" not in st.session_state:
    st.session_state.images_encoded = []

# ì´ë¯¸ì§€ ì—…ë¡œë“œ
images_uploaded = st.file_uploader("ì—¬ëŸ¬ ì¥ì˜ ì‚¬ì§„ì„ ì˜¬ë ¤ì£¼ì„¸ìš”!", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)

# ì´ë¯¸ì§€ê°€ ìƒˆë¡œ ì—…ë¡œë“œë˜ì—ˆì„ ê²½ìš° ì¸ì½”ë”©í•˜ì—¬ ì„¸ì…˜ì— ì €ì¥
if images_uploaded:
    if len(images_uploaded) < 1:
        st.warning("ìµœì†Œ í•œ ì¥ ì´ìƒì˜ ì´ë¯¸ì§€ë¥¼ ì˜¬ë ¤ì£¼ì„¸ìš”!")
    else:
        # ì´ë¯¸ì§€ base64 ì¸ì½”ë”©
        images_encoded = []
        for image in images_uploaded:
            images_encoded.append(base64.b64encode(image.read()).decode("utf-8"))
        
        # ì´ë¯¸ì§€ - ì„¸ì…˜ ì €ì¥    
        st.session_state.images_encoded = images_encoded
        
        st.image(images_uploaded, caption=[f"ì´ë¯¸ì§€ {i + 1}" for i in range(len(images_uploaded))])
        st.success(f"{len(images_uploaded)} ì¥ì˜ ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì§ˆë¬¸í•´ ë³´ì„¸ìš”!")

# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ì— ëŒ€í•´ ë¬´ì—‡ì´ ê¶ê¸ˆí•œê°€ìš”?")
    
# GPT í˜¸ì¶œ
if user_input and st.session_state.images_encoded:
    # ì‚¬ìš©ì ì§ˆë¬¸ - í™”ë©´ ì¶œë ¥
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # ì‚¬ìš©ì ì§ˆë¬¸ - ì„¸ì…˜ ì €ì¥
    st.session_state.messages.append({"role": "user", "content": user_input})

    # GPT ë©”ì‹œì§€ êµ¬ì„± (í…ìŠ¤íŠ¸(ì‚¬ìš©ì ì§ˆë¬¸) + ì´ë¯¸ì§€ ë‹¤ìˆ˜)
    content = [{"type": "text", "text": user_input}]
    for image_encoded in st.session_state.images_encoded:
        content.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{image_encoded}"}
        })

    # GPT ì‘ë‹µ
    message = HumanMessage(content=content)
    result = model.invoke([message])
    response = result.content

    with st.chat_message("assistant"):
        st.markdown(response)

    st.session_state.messages.append({"role": "assistant", "content": response})

elif user_input and not st.session_state.images_encoded:
    st.warning("ì§ˆë¬¸ ì „ì— ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ì˜¬ë ¤ì£¼ì„¸ìš”!")